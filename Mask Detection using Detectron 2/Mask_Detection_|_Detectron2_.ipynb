{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushs0911/Object-Detection/blob/main/Mask_Detection_%7C_Detectron2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import json\n",
        "import xml.etree.ElementTree as ET"
      ],
      "metadata": {
        "id": "5vfeKW4VgaEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvuIFMDtAzX7"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d andrewmvd/face-mask-detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/face-mask-detection.zip"
      ],
      "metadata": {
        "id": "dth2HZA2BrGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n"
      ],
      "metadata": {
        "id": "OOZRixEgCBQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "q41s7DYdCLPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "SivgNbQgCrzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualisation"
      ],
      "metadata": {
        "id": "WmWlGkvuWX6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"with_mask\", \"without_mask\", \"mask_weared_incorrect\"]\n",
        "N_Classes = 3\n",
        "H,W =224,224\n",
        "SPLIT_SIZE=H//32\n",
        "N_EPOCHS=135\n",
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "id": "mt-Y4PyHW0gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_xml(filename):\n",
        "    tree = ET.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    size_tree = root.find('size')\n",
        "    height = float(size_tree.find(\"height\").text)\n",
        "    width = float(size_tree.find(\"width\").text)\n",
        "    depth = float(size_tree.find(\"depth\").text)\n",
        "    \n",
        "    bounding_boxes = []\n",
        "    \n",
        "    for object_tree in root.findall('object'):\n",
        "        for bounding_box in object_tree.iter('bndbox'):\n",
        "            xmin = (float(bounding_box.find('xmin').text))\n",
        "            ymin = (float(bounding_box.find('ymin').text))\n",
        "            xmax = (float(bounding_box.find('xmax').text))\n",
        "            ymax = (float(bounding_box.find('ymax').text))\n",
        "            \n",
        "            break\n",
        "        class_name = object_tree.find('name').text\n",
        "        class_dict = {classes[i]:i for i in range(len(classes))}\n",
        "        bounding_box = [\n",
        "            (xmin + xmax)/(2*width), #x-center\n",
        "            (ymin + ymax)/(2*height), #ycenter\n",
        "            (xmax - xmin)/width, #box-width\n",
        "            (ymax - ymin)/height, #box height\n",
        "            class_dict[class_name]\n",
        "        ]\n",
        "        bounding_boxes.append(bounding_box)\n",
        "    return (bounding_boxes)\n",
        "        \n",
        "    "
      ],
      "metadata": {
        "id": "pivqyRlQWbiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = (\"/content/images/\")\n",
        "train_maps = (\"/content/annotations/\")"
      ],
      "metadata": {
        "id": "8Eb9I1v1WcwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_paths = []\n",
        "xml_paths = []\n",
        "\n",
        "for i in os.listdir(train_maps):\n",
        "  im_paths.append(train_images + i[:-3]+'png')\n",
        "  xml_paths.append(train_maps + i)"
      ],
      "metadata": {
        "id": "4RJCN4FkWhnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_bbox(image, bounding_box, class_names):\n",
        "    \"\"\"\n",
        "    Plots the given bounding box on the image.\n",
        "\n",
        "    Parameters:\n",
        "    image (numpy.ndarray): The image to plot the bounding box on.\n",
        "    bounding_box (tuple): A tuple representing the bounding box in the format (x_center, y_center, box_width, box_height, class_index).\n",
        "    class_names (list): A list of strings representing the names of the classes.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Get the image dimensions\n",
        "    height, width, _ = image.shape\n",
        "    \n",
        "    # Create a figure and axes object\n",
        "    fig, ax = plt.subplots(1)\n",
        "\n",
        "    # Calculate the coordinates of the bounding box\n",
        "    for i in range(0, len(bounding_box)):\n",
        "        x_center, y_center, box_width, box_height, class_index = tuple(bounding_box[i])\n",
        "        xmin = int((x_center - box_width / 2) * width)\n",
        "        xmax = int((x_center + box_width / 2) * width)\n",
        "        ymin = int((y_center - box_height / 2) * height)\n",
        "        ymax = int((y_center + box_height / 2) * height)\n",
        "\n",
        "        # Get the class name from the class index\n",
        "        class_name = class_names[class_index]\n",
        "\n",
        "        # Create a rectangle patch for the bounding box\n",
        "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        \n",
        "\n",
        "        # Display the image on the axes\n",
        "        plt.imshow(image)\n",
        "\n",
        "        # Add the rectangle patch to the axes\n",
        "        \n",
        "\n",
        "        # Add the class name to the axes\n",
        "        if class_index == 0:\n",
        "            ax.text(xmin, ymin, class_name, fontsize=10, color='green')\n",
        "        elif class_index == 1:\n",
        "            ax.text(xmin, ymin, class_name, fontsize=10, color='red')\n",
        "        else:\n",
        "            ax.text(xmin, ymin, class_name, fontsize=10, color='yellow')\n",
        "            \n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ejyHIFEOWlJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10,21):\n",
        "    plot_bbox(image = plt.imread(im_paths[i]),\n",
        "            bounding_box = preprocess_xml(xml_paths[i]),\n",
        "            class_names = classes)"
      ],
      "metadata": {
        "id": "ZXkzej8yWqNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on Custom Dataset "
      ],
      "metadata": {
        "id": "2-x_h4TuDUDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "\n",
        "def convert_xml_to_coco(xml_dir):\n",
        "    dataset_dicts = []\n",
        "    image_id = 0\n",
        "    annotation_id = 0\n",
        "\n",
        "\n",
        "    # Set categories (modify as per your dataset)\n",
        "    categories = [\n",
        "        {\"id\": 0, \"name\": \"with_mask\", \"supercategory\": \"object\"},\n",
        "        {\"id\": 1, \"name\": \"without_mask\", \"supercategory\": \"object\"},\n",
        "        {\"id\": 2, \"name\": \"mask_weared_incorrect\", \"supercategory\": \"object\"}\n",
        "\n",
        "        # Add more categories as needed\n",
        "    ]\n",
        "    \n",
        "    # Iterate over XML files\n",
        "    for filename in os.listdir(xml_dir):\n",
        "        if not filename.endswith(\".xml\"):\n",
        "            continue\n",
        "\n",
        "        xml_path = os.path.join(xml_dir, filename)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        image_name = root.find(\"filename\").text.replace(\".xml\", \".png\")\n",
        "\n",
        "        # Get image information\n",
        "        width = int(root.find(\"size/width\").text)\n",
        "        height = int(root.find(\"size/height\").text)\n",
        "        \n",
        "        record = {\n",
        "            \"file_name\": \"/content/images/\" + image_name,\n",
        "            \"image_id\": image_id,\n",
        "            \"height\": height,\n",
        "            \"width\": width,\n",
        "            \"annotations\": []\n",
        "        }\n",
        "        \n",
        "        # Process object annotations\n",
        "        for obj in root.findall(\"object\"):\n",
        "            category_name = obj.find(\"name\").text\n",
        "            category_id = [c[\"id\"] for c in categories if c[\"name\"] == category_name][0]\n",
        "\n",
        "            bbox = obj.find(\"bndbox\")\n",
        "            xmin = float(bbox.find(\"xmin\").text)\n",
        "            ymin = float(bbox.find(\"ymin\").text)\n",
        "            xmax = float(bbox.find(\"xmax\").text)\n",
        "            ymax = float(bbox.find(\"ymax\").text)\n",
        "\n",
        "            width1 = xmax - xmin\n",
        "            height1 = ymax - ymin\n",
        "\n",
        "            annotation = {\n",
        "                \"bbox\": [xmin, ymin, xmax, ymax],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [],\n",
        "                \"category_id\": category_id,\n",
        "                \"category_name\" : category_name,\n",
        "                \"image_id\": image_id,\n",
        "                \"iscrowd\": 0,  # Modify as needed\n",
        "                \"area\": width1 * height1,\n",
        "            }\n",
        "            record[\"annotations\"].append(annotation)\n",
        "\n",
        "            annotation_id += 1\n",
        "\n",
        "        dataset_dicts.append(record)\n",
        "        image_id += 1\n",
        "\n",
        "    return dataset_dicts\n"
      ],
      "metadata": {
        "id": "Nl1yrwzKigSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "# DatasetCatalog.register(\"MASK_detec\", lambda: convert_xml_to_coco(xml_dir = \"/content/annotations/\",\n",
        "#                                                                       images_dir = \"/content/images/\"))\n",
        "# MetadataCatalog.get(\"MASK_detec\").set(things_cluster = [\"with_mask\", \"without_mask\", \"mask_weared_incorrect\" ])"
      ],
      "metadata": {
        "id": "B0VeYvoBeFZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in [\"annotations\"]:\n",
        "    DatasetCatalog.register(\"5\" + d, lambda d=d: convert_xml_to_coco(\"/content/\" + d + \"/\"))\n",
        "    MetadataCatalog.get(\"5\" + d).set(thing_classes=[\"with_mask\", \"without_mask\", \"mask_weared_incorrect\"])\n",
        "mask_metadata = MetadataCatalog.get(\"5annotations\")"
      ],
      "metadata": {
        "id": "hr1mY3--0ATY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_metadata"
      ],
      "metadata": {
        "id": "lo-LXrje1Cle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify the dataset is in correct form, let's visualize the annotations of randomly selected samlples in training set. "
      ],
      "metadata": {
        "id": "JdMAEXzffI2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dicts = convert_xml_to_coco(xml_dir = \"/content/annotations/\")\n",
        "random.sample(dataset_dicts,1)"
      ],
      "metadata": {
        "id": "Sh2709NP1IqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in random.sample(dataset_dicts, 3):\n",
        "  img = cv2.imread(d[\"file_name\"])\n",
        "  visualizer = Visualizer(img[:,:,::-1], metadata=mask_metadata, scale= 1)\n",
        "  out = visualizer.draw_dataset_dict(d)\n",
        "  cv2_imshow(out.get_image()[:,:,::-1])"
      ],
      "metadata": {
        "id": "dXV48zNpfjEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train "
      ],
      "metadata": {
        "id": "F24Tl4-1XZAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's fine tune a COCO-pretrained R50-FPN Mask R-CNN model on the mask datacet. "
      ],
      "metadata": {
        "id": "BpZlb_4QXaRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"4annotations\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 2000   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "MNcaU30EN6yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # # Look at training curves in tensorboard:\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir output"
      ],
      "metadata": {
        "id": "yB3S5ap04AJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference & evaluation using the trained model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u3dbbh2L49el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = \"/content/output/model_final.pth\"  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.65 # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "v7YAy6C54UpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor(cv2.imread(\"/content/images/maksssksksss100.png\"))"
      ],
      "metadata": {
        "id": "TOS2kIePAJIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rbo-wppsAIvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from detectron2.utils.visualizer import ColorMode\n",
        "# dataset_dicts = get_balloon_dicts(\"balloon/val\")\n",
        "# for d in random.sample(dataset_dicts, 3):    \n",
        "#     im = cv2.imread(d[\"file_name\"])\n",
        "#     outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "#     v = Visualizer(im[:, :, ::-1],\n",
        "#                    metadata=balloon_metadata, \n",
        "#                    scale=0.5, \n",
        "#                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "#     )\n",
        "#     out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "#     cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "K2-nmHcN6kGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "QCs0j3J6asPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d itsezsid/facemask-darknet"
      ],
      "metadata": {
        "id": "Dfy-OSay45Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/facemask-darknet.zip"
      ],
      "metadata": {
        "id": "fbMM1-XI68IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_files = []\n",
        "for filename in os.listdir(\"/content/test/\"):\n",
        "  if filename.endswith(\".jpg\"):\n",
        "    test_files.append(filename)"
      ],
      "metadata": {
        "id": "EOCKwAHl7b-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "# Create subplots for displaying multiple images\n",
        "fig, axs = plt.subplots(3, 3, figsize=(30, 30))\n",
        "\n",
        "# Iterate over a sample of test images\n",
        "for i, image_path in enumerate(random.sample(test_files, 9)):\n",
        "    # Read the image\n",
        "    image = plt.imread(\"/content/test/\" + image_path)\n",
        "    \n",
        "    # Perform object detection on the image\n",
        "    outputs = predictor(image)\n",
        "    \n",
        "    # Create a Visualizer\n",
        "    visualizer = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg.DATASETS.TRAIN[0]))\n",
        "    \n",
        "    # Draw the predicted bounding boxes on the image\n",
        "    vis_output = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    \n",
        "    # Get the image with drawn predictions\n",
        "    output_image = vis_output.get_image()[:, :, ::-1]\n",
        "    \n",
        "    # Display the image\n",
        "    axs[i // 3, i % 3].imshow(output_image)\n",
        "    axs[i // 3, i % 3].axis(\"off\")\n"
      ],
      "metadata": {
        "id": "mQuv5XsTcQQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cKumzi7aN_tJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
