# -*- coding: utf-8 -*-
"""Yolov8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xGesR9gNL-yL3GI8bzUCspz04rnQ3qBt
"""

!nvidia-smi -L

"""# Importing Libraries """

import numpy as np 
import pandas as pd
import os
import cv2 as cv
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from glob import glob
from tqdm.notebook import tqdm
tqdm.pandas()
import random
import json
from sklearn.model_selection import train_test_split
import shutil
import yaml

"""# Downloading Dataset"""

!pip install -q kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json
!kaggle datasets download -d mistag/arthropod-taxonomy-orders-object-detection-dataset

!unzip /content/arthropod-taxonomy-orders-object-detection-dataset.zip

"""# Data Handling"""

BASE_DIR = "/content/"
annotation_list = glob("/content/ArTaxOr/*/annotations/*.json")

data = pd.DataFrame()
data['annotation_dir'] = annotation_list

data.head()

"""This function reads object detection data from a JSON file and returns a dictionary containing the required data. Here is a brief explanation of what this function does:

- It creates a dictionary named `rows` to store the extracted data.
- It opens the JSON file and reads its contents using the `json` library.
- For each region (i.e., object) in the JSON file, it extracts the following information:
  - The image directory.
  - The species type.
  - The image width and height.
  - The normalized bounding box height, width, left, and top coordinates.
  - The x and y center coordinates of the bounding box.
- It returns the `rows` dictionary containing the extracted data.

Overall, this function is used to read the object detection data from a JSON file and prepare it for use in training an object detection model.
"""

def read_json_data(jsonfile):
    rows = {"img_dir":[] ,"img_w":[] , "img_h" : [], "sp_type": [] ,"xc":[] , "yc":[], "bb_height" : [] , "bb_width": [] , "bb_left":[] , "bb_top":[]}
    
    # read file
    json_f = open(jsonfile)
    json_f = json.load(json_f)
 
    for region in json_f["regions"]:
        img_dir = json_f["asset"]["path"][7:]
        
        sp_type = region["tags"][0]
        
        img_w = json_f["asset"]["size"]["width"]
        img_h = json_f["asset"]["size"]["height"]
        
        # Normalize Bounding Box 
        bb_height = region["boundingBox"]["height"] / img_h
        bb_width = region["boundingBox"]["width"] / img_w
        
        bb_left = region["boundingBox"]["left"] / img_w
        bb_top = region["boundingBox"]["top"] / img_h
        
        xcenter = region['boundingBox']['left']/img_w+0.5*bb_width
        ycenetr = region['boundingBox']['top']/img_h+0.5*bb_height
        
        rows["img_dir"].append(BASE_DIR+img_dir)
        rows["sp_type"].append(sp_type)
        rows["img_w"].append(img_w)
        rows["img_h"].append(img_h)
        rows["bb_height"].append(bb_height)
        rows["bb_width"].append(bb_width)
        rows["bb_left"].append(bb_left)
        rows["bb_top"].append(bb_top)
        rows["xc"].append(xcenter)
        rows["yc"].append(ycenetr)

    return rows

df = pd.DataFrame()

read_json_data("/content/ArTaxOr/Coleoptera/annotations/ee94e248ec9e55792441e992fff5bf10-asset.json")

for json_file in tqdm(data["annotation_dir"]):
  rows = read_json_data(json_file)
  df = df.append(df.from_dict(rows))

df = df.reset_index(drop = True)
df.head()

df['sp_type'].value_counts().plot(kind = 'bar')

"""#Data Visualization """

def display_random_imgs(df , rows , cols):
  idxs = random.sample(df.index.tolist() , rows*cols)
  fig , ax = plt.subplots(rows , cols ,figsize = (10,10))
  if rows*cols != 1:
    for count , axs in enumerate(ax.flatten()):
      path = df.img_dir.iloc[idxs[count]]
      patch = patches.Rectangle((df.bb_left.iloc[idxs[count]] * df.img_w.iloc[idxs[count]],
                                  df.bb_top.iloc[idxs[count]]* df.img_h.iloc[idxs[count]]),
                                df.bb_width.iloc[idxs[count]]* df.img_w.iloc[idxs[count]],
                                df.bb_height.iloc[idxs[count]]* df.img_h.iloc[idxs[count]],
                                linewidth=1, edgecolor='r', facecolor='none')
      img = plt.imread(path)
      axs.imshow(img)
      axs.add_patch(patch)
      axs.axis('off')
      axs.title.set_text(df.sp_type.iloc[idxs[count]])

display_random_imgs(df ,5, 3)

"""#Model"""

classes_name = ["Hymenoptera","Hemiptera","Lepidoptera","Coleoptera","Diptera","Araneae","Odonata"]
classes_num = [0,1,2,3,4,5,6]

df.sp_type = df.sp_type.replace(classes_name , classes_num)

train, test = train_test_split(df, test_size = 0.2)

!mkdir data 
!mkdir data/train
!mkdir data/test

def add_data_to_folder(file_type, data):
    for index, row  in tqdm(data.iterrows(),total=len(data)):
        shutil.copy(row["img_dir"] , f"/content/data/{file_type}")
        with open(f'/content/data/{file_type}/{row.img_dir.split("/")[-1][:-4]}.txt' , "w") as f:
            f.write(str(row["sp_type"]))
            f.write(" ")
            f.write(str(row["xc"]))
            f.write(" ")
            f.write(str(row["yc"]))
            f.write(" ")
            f.write(str(row["bb_width"]))
            f.write(" ")
            f.write(str(row["bb_height"]))
            f.write("\n")
            f.close()

add_data_to_folder("train/" , train)
add_data_to_folder("test/" , test)

"""## Coloning YOLO github repository"""

!git clone https://github.com/ultralytics/yolov5
!mv yolov5/* ./

# Commented out IPython magic to ensure Python compatibility.
# create yml file
yaml_dict = dict(
    train = '/content/data/train',
    val = '/content/data/test',
    
    nc    = len(classes_num), # number of classes
    names = classes_name # classes
    )

with open('/content/data.yaml', 'w') as outfile:
    yaml.dump(yaml_dict, outfile, default_flow_style=False)

# %cat /content/data.yaml

! pip install ultralytics

import ultralytics
from IPython import display
display.clear_output()
!yolo checks

from ultralytics import YOLO

"""##Defining Model """

# Load a model
model = YOLO("yolov8n.pt")  # load a pretrained model (recommended for training)
batch_size = 32
imgsz = 640

del df , data

"""## Training """

# Use the model
results = model.train(data="data.yaml", 
                      epochs = 1 , 
                      batch = batch_size , 
                      imgsz=imgsz)  # train the model

model.val()

from PIL import Image
from glob import glob
from os import path
import cv2
import matplotlib.pyplot as plt
import os

im = Image.open("/content/ArTaxOr/Lepidoptera/00026d79d067.jpg")

results = model.predict(im, save = True)

results = model.predict(Image.open("/content/data/test/00600a41bcaf.jpg"), save = True)

"""##Re-Training """

model = YOLO("/content/runs/detect/train/weights/best.pt")
batch_size = 32
imgsz = 640

# Use the model
results = model.train(data="data.yaml", 
                      epochs = 1 , 
                      batch = batch_size , 
                      imgsz=imgsz)  # train the model

"""#Testing """

import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding

!pip install -q kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json
! kaggle datasets download -d mistag/arthropod-taxonomy-orders-object-detection-testset

!unzip arthropod-taxonomy-orders-object-detection-testset

from glob import glob
from os import path
from PIL import Image

test_set = "/content/ArTaxOr_TestSet/positives"

test_images = [Image.open(jpg) for jpg in glob(path.join(test_set, '*.jpg'))]

test = [jpg for jpg in glob(path.join(test_set, '*.jpg'))]

results = model(test)

plt.imshow(results[10].plot(font_size = (7,), 
                            line_width = (7)))

# for img in test_images:
#   results = model.predict(img, save = True,)

plt.figure(figsize = (20,14))
for i, filename in enumerate(results):
  # img = cv2.imread(os.path.join(output, filename))
  ax = plt.subplot(4,4,i+1)
  plt.imshow(cv2.cvtColor(filename.plot(font_size = (10,), line_width = (7)), cv2.COLOR_BGR2RGB))
  plt.axis('off')
  if i == 15:
    break
plt.savefig('image')

"""#Export"""

model.export(format='onnx', dynamic=True)